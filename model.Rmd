---
title: "Machine Learning"
output:
  html_document:
    df_print: paged
  keep_md: yes
  html_notebook: null
---
```{r global-options, include = FALSE}

knitr::opts_chunk$set(fig.width=6, fig.height=3, dpi= 800,
                      echo=TRUE, warning=FALSE, message=FALSE)
```

# Summary

Here I will demonstrate how **Da BiG BoYz** do machine learning and develop
a model with over 99% accuracy cuz **iMa BeAsT** at R.

# Description of Dataset
**SOURCE: linked website**

This human activity recognition research has traditionally focused on 
discriminating between different activities, i.e. to predict "which" activity 
was performed at a specific point in time (like with the Daily Living Activities dataset above). The approach we propose for the Weight Lifting Exercises
dataset is to investigate "how (well)" an activity was performed by the wearer. 
The "how (well)" investigation has only received little attention so far, even 
though it potentially provides useful information for a large variety of applications,such as sports training.

In this work (see the paper) we first define quality of execution and 
investigate three aspects that pertain to qualitative activity recognition: the problem of specifying correct execution, the automatic and robust detection of execution mistakes, and how to provide feedback on the quality of execution to 
the user. We tried out an on-body sensing approach (dataset here), but also an "ambient sensing approach" (by using Microsoft Kinect - dataset still 
unavailable)

Six young health participants were asked to perform one set of 10 repetitions of 
the Unilateral Dumbbell Biceps Curl in five different fashions: exactly 
according to the specification (Class A), throwing the elbows to the front 
(Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell 
only halfway (Class D) and throwing the hips to the front (Class E).


```{r}
library(caret); library(randomForest); library(tidyverse)

data <- read.csv("pml-training.csv")
```

_**The key to getting 99% accuracy is to drop unnecessary columns**_

When we load in the data we see immediately that there are blank ("") elements
and columns with NA values. We also see that the first column is simply the
index which is not needed. We also see that "classe" is misspelled and is at
the end of the dataframe but isn't a big deal.

We also don't care about the user_name and time columns. Timestamps do not
matter because it is unlikely to have an effect on the outcome variable.

The new_window column can be dropped as well. Inspecting the column with the 
count function (i.e count(train,new_window)), there are 19216 no's and 406 yes's
so how useful would this really be?? 

```{r}
#process the training and test sets
#use select_if to ignore columns that have any element containing an NA value
data <- data %>% na_if("") %>% select_if(~!anyNA(.)) %>% select(-(1:7))

#in order to do random forests, classe must be a factor variable
data$classe <- as.factor(data$classe)
```

Split data into train and test sets
```{r}
inTrain <- createDataPartition(data$classe, p = .75)[[1]]#get first element
#make data sets
train <- data[inTrain,]
test <- data[-inTrain,]

```

Let's fit a random forest model. The key here is to go directly to the rf
package and not use caret's train function.
```{r}
rf <- randomForest(classe~., data = train)
#using train via caret package is too slow
#train(classe ~., method = "rf", prox = TRUE, data = train)
```

```{r}
preds <- predict(rf, newdata = test[-53])
cm <- confusionMatrix(test$classe, preds)
show(cm)
```
The metrics look fantastic. With over 99% accuracy and a "no information rate"
of 2.9 combined with an extremely small p-val indicates our model is robust.

Let's plot the confusion matrix. We can get the matrix values out of the cm
list object, then we can convert to a data frame and use geom_tile()
```{r}
cm.vals <- as.data.frame(cm[[2]])
ggplot(data = cm.vals, aes(x = Reference, y = Prediction, fill = Freq)) + 
  geom_tile(color = "black") +
  scale_fill_gradient2(low = "yellow", high = "red", mid = "green",
                       limit = c(0,1395), midpoint = 1395/2,
                       space = "Lab", name = "Matrix Vals") +
  geom_text(aes(Reference, Prediction, label = Freq), 
            color = "black", size = 6) +
  theme_minimal() + labs(title = "Random Forest Confusion Matrix")

```



Now lets apply our model to the test data set for the quiz
```{r}
testquiz  <- read.csv("pml-testing.csv")
testquiz  <- testquiz %>% na_if("") %>% select_if(~!anyNA(.)) %>% select(-(1:7))

preds.quiz <- predict(rf, newdata = testquiz)
show(preds.quiz)
```